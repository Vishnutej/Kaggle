{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape (28709L, 48L, 48L)\n",
      "X_train shape: (28709L, 1L, 48L, 48L)\n",
      "28709 train samples\n",
      "3589 test samples\n",
      "Y_train shape (28709L, 7L)\n",
      "Train on 28709 samples, validate on 3589 samples\n",
      "Epoch 1/50\n",
      "28709/28709 [==============================] - 1162s - loss: 1.8401 - acc: 0.2372 - val_loss: 1.8132 - val_acc: 0.2494\n",
      "Epoch 2/50\n",
      "28709/28709 [==============================] - 1292s - loss: 1.8218 - acc: 0.2487 - val_loss: 1.8105 - val_acc: 0.2494\n",
      "Epoch 3/50\n",
      "28709/28709 [==============================] - 1304s - loss: 1.8048 - acc: 0.2524 - val_loss: 1.7690 - val_acc: 0.2508\n",
      "Epoch 4/50\n",
      "28709/28709 [==============================] - 1243s - loss: 1.6965 - acc: 0.3127 - val_loss: 1.6323 - val_acc: 0.3555\n",
      "Epoch 5/50\n",
      "28709/28709 [==============================] - 1195s - loss: 1.5679 - acc: 0.3822 - val_loss: 1.5218 - val_acc: 0.4074\n",
      "Epoch 6/50\n",
      "28709/28709 [==============================] - 1200s - loss: 1.4735 - acc: 0.4233 - val_loss: 1.5351 - val_acc: 0.4060\n",
      "Epoch 7/50\n",
      "28709/28709 [==============================] - 1291s - loss: 1.3902 - acc: 0.4652 - val_loss: 1.4310 - val_acc: 0.4425\n",
      "Epoch 8/50\n",
      "28709/28709 [==============================] - 1326s - loss: 1.3197 - acc: 0.4948 - val_loss: 1.3216 - val_acc: 0.4767\n",
      "Epoch 9/50\n",
      "28709/28709 [==============================] - 3102s - loss: 1.2636 - acc: 0.5186 - val_loss: 1.4401 - val_acc: 0.4232\n",
      "Epoch 10/50\n",
      "28709/28709 [==============================] - 1074s - loss: 1.2156 - acc: 0.5387 - val_loss: 1.2235 - val_acc: 0.5261\n",
      "Epoch 11/50\n",
      "28709/28709 [==============================] - 4180s - loss: 1.1695 - acc: 0.5595 - val_loss: 1.2316 - val_acc: 0.5492\n",
      "Epoch 12/50\n",
      "28709/28709 [==============================] - 21100s - loss: 1.1301 - acc: 0.5771 - val_loss: 1.2003 - val_acc: 0.5380\n",
      "Epoch 13/50\n",
      "28709/28709 [==============================] - 1313s - loss: 1.0864 - acc: 0.5939 - val_loss: 1.1698 - val_acc: 0.5553\n",
      "Epoch 14/50\n",
      "28709/28709 [==============================] - 1432s - loss: 1.0472 - acc: 0.6085 - val_loss: 1.1309 - val_acc: 0.5832\n",
      "Epoch 15/50\n",
      "28709/28709 [==============================] - 1323s - loss: 1.0005 - acc: 0.6306 - val_loss: 1.1508 - val_acc: 0.5720\n",
      "Epoch 16/50\n",
      "28709/28709 [==============================] - 1113s - loss: 0.9608 - acc: 0.6432 - val_loss: 1.3765 - val_acc: 0.5300\n",
      "Epoch 17/50\n",
      "28709/28709 [==============================] - 1115s - loss: 0.9131 - acc: 0.6624 - val_loss: 1.1310 - val_acc: 0.5846\n",
      "Epoch 18/50\n",
      "28709/28709 [==============================] - 2379s - loss: 0.8678 - acc: 0.6808 - val_loss: 1.1482 - val_acc: 0.5790\n",
      "Epoch 19/50\n",
      "28709/28709 [==============================] - 1293s - loss: 0.8264 - acc: 0.6955 - val_loss: 1.2940 - val_acc: 0.5461\n",
      "Epoch 20/50\n",
      "28709/28709 [==============================] - 1130s - loss: 0.7689 - acc: 0.7195 - val_loss: 1.1570 - val_acc: 0.6004\n",
      "Epoch 21/50\n",
      "28709/28709 [==============================] - 1145s - loss: 0.7228 - acc: 0.7376 - val_loss: 1.2379 - val_acc: 0.5790\n",
      "Epoch 22/50\n",
      "28709/28709 [==============================] - 1226s - loss: 0.6713 - acc: 0.7565 - val_loss: 1.2702 - val_acc: 0.5982\n",
      "Epoch 23/50\n",
      "28709/28709 [==============================] - 1178s - loss: 0.6304 - acc: 0.7744 - val_loss: 1.2980 - val_acc: 0.6002\n",
      "Epoch 24/50\n",
      "28709/28709 [==============================] - 1275s - loss: 0.5744 - acc: 0.7944 - val_loss: 1.3744 - val_acc: 0.5887\n",
      "Epoch 25/50\n",
      "28709/28709 [==============================] - 1383s - loss: 0.5225 - acc: 0.8108 - val_loss: 1.4103 - val_acc: 0.5840\n",
      "Epoch 26/50\n",
      "28709/28709 [==============================] - 1546s - loss: 0.4740 - acc: 0.8283 - val_loss: 1.5502 - val_acc: 0.5795\n",
      "Epoch 27/50\n",
      "28709/28709 [==============================] - 1655s - loss: 0.4315 - acc: 0.8462 - val_loss: 1.5774 - val_acc: 0.5940\n",
      "Epoch 28/50\n",
      "28709/28709 [==============================] - 1652s - loss: 0.3993 - acc: 0.8567 - val_loss: 1.6630 - val_acc: 0.5952\n",
      "Epoch 29/50\n",
      "28709/28709 [==============================] - 1712s - loss: 0.3591 - acc: 0.8736 - val_loss: 1.7312 - val_acc: 0.5862\n",
      "Epoch 30/50\n",
      "28709/28709 [==============================] - 1645s - loss: 0.3261 - acc: 0.8848 - val_loss: 1.8031 - val_acc: 0.5991\n",
      "Epoch 31/50\n",
      "28709/28709 [==============================] - 1699s - loss: 0.2926 - acc: 0.8984 - val_loss: 1.8086 - val_acc: 0.5784\n",
      "Epoch 32/50\n",
      "28709/28709 [==============================] - 1560s - loss: 0.2657 - acc: 0.9074 - val_loss: 1.9047 - val_acc: 0.6010\n",
      "Epoch 33/50\n",
      "28709/28709 [==============================] - 1369s - loss: 0.2543 - acc: 0.9121 - val_loss: 2.0119 - val_acc: 0.5851\n",
      "Epoch 34/50\n",
      "28709/28709 [==============================] - 1284s - loss: 0.2322 - acc: 0.9193 - val_loss: 2.1424 - val_acc: 0.6004\n",
      "Epoch 35/50\n",
      "28709/28709 [==============================] - 1324s - loss: 0.2059 - acc: 0.9284 - val_loss: 2.1056 - val_acc: 0.5921\n",
      "Epoch 36/50\n",
      "28709/28709 [==============================] - 1324s - loss: 0.2011 - acc: 0.9316 - val_loss: 2.2997 - val_acc: 0.5787\n",
      "Epoch 37/50\n",
      "28709/28709 [==============================] - 26923s - loss: 0.1864 - acc: 0.9358 - val_loss: 2.4150 - val_acc: 0.5648\n",
      "Epoch 38/50\n",
      "28709/28709 [==============================] - 1272s - loss: 0.1718 - acc: 0.9427 - val_loss: 2.4127 - val_acc: 0.5768\n",
      "Epoch 39/50\n",
      "28709/28709 [==============================] - 1322s - loss: 0.1657 - acc: 0.9426 - val_loss: 2.3142 - val_acc: 0.5932\n",
      "Epoch 40/50\n",
      "28709/28709 [==============================] - 1278s - loss: 0.1533 - acc: 0.9477 - val_loss: 2.4686 - val_acc: 0.5965\n",
      "Epoch 41/50\n",
      "28709/28709 [==============================] - 1202s - loss: 0.1449 - acc: 0.9523 - val_loss: 2.3714 - val_acc: 0.5938\n",
      "Epoch 42/50\n",
      "28709/28709 [==============================] - 1259s - loss: 0.1354 - acc: 0.9545 - val_loss: 2.6431 - val_acc: 0.5840\n",
      "Epoch 43/50\n",
      "28709/28709 [==============================] - 1175s - loss: 0.1342 - acc: 0.9555 - val_loss: 2.8033 - val_acc: 0.5910\n",
      "Epoch 44/50\n",
      "28709/28709 [==============================] - 1335s - loss: 0.1360 - acc: 0.9543 - val_loss: 2.4159 - val_acc: 0.5918\n",
      "Epoch 45/50\n",
      "28709/28709 [==============================] - 1245s - loss: 0.1171 - acc: 0.9612 - val_loss: 2.7967 - val_acc: 0.5754\n",
      "Epoch 46/50\n",
      "28709/28709 [==============================] - 1228s - loss: 0.1137 - acc: 0.9633 - val_loss: 2.5889 - val_acc: 0.6024\n",
      "Epoch 47/50\n",
      "28709/28709 [==============================] - 1253s - loss: 0.1094 - acc: 0.9637 - val_loss: 2.9548 - val_acc: 0.5940\n",
      "Epoch 48/50\n",
      "28709/28709 [==============================] - 1195s - loss: 0.1090 - acc: 0.9643 - val_loss: 2.6699 - val_acc: 0.5929\n",
      "Epoch 49/50\n",
      "28709/28709 [==============================] - 1305s - loss: 0.0994 - acc: 0.9678 - val_loss: 2.7165 - val_acc: 0.6041\n",
      "Epoch 50/50\n",
      "28709/28709 [==============================] - 1371s - loss: 0.1044 - acc: 0.9661 - val_loss: 2.9723 - val_acc: 0.5910\n",
      "3589/3589 [==============================] - 44s    \n",
      "['loss', 'acc']\n",
      "Test score: 2.97230684017\n",
      "Test accuracy: 0.590972415723\n",
      "3589/3589 [==============================] - 43s    \n",
      "Predictions: [0 0 0 ..., 4 0 6]\n",
      "3589/3589 [==============================] - 46s    \n",
      "Probablities:\n",
      "[[  9.99100208e-01   1.70458270e-06   1.74402929e-04 ...,   6.96181145e-04\n",
      "    2.43725345e-10   2.74532795e-05]\n",
      " [  3.63584429e-01   3.52709472e-01   2.61961430e-01 ...,   2.13699695e-02\n",
      "    1.28760678e-06   2.90566008e-04]\n",
      " [  9.99449909e-01   1.39087228e-06   5.46449213e-04 ...,   2.26493421e-06\n",
      "    4.35721381e-12   4.14813184e-11]\n",
      " ..., \n",
      " [  1.18110853e-04   5.08285192e-10   1.99586269e-03 ...,   9.08139586e-01\n",
      "    3.95482758e-08   8.96865875e-02]\n",
      " [  8.53749275e-01   4.19035450e-06   1.61455682e-04 ...,   1.45943642e-01\n",
      "    3.42821993e-09   2.20683319e-06]\n",
      " [  3.92264873e-02   6.08292466e-05   2.26456206e-02 ...,   3.45961750e-01\n",
      "    1.13074639e-05   5.92085302e-01]]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th') #Use Theano\n",
    "\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "#Training set size\n",
    "train_size = 28709\n",
    "\n",
    "#Test set size\n",
    "test_size = 3589\n",
    "\n",
    "#Dimensions of the image\n",
    "dim = 48\n",
    "\n",
    "#Numpy Arrays -Train\n",
    "X_train = np.empty([train_size,dim, dim])\n",
    "y_train = np.empty(train_size)\n",
    "\n",
    "#Numpy Arrays -Test\n",
    "X_test = np.empty([test_size, dim, dim])\n",
    "y_test = np.empty(test_size)\n",
    "    \n",
    "#File - Change path as required    \n",
    "f = open('C:/Users/Vishnutej/Desktop/fer2013/fer2013.csv', 'rb')\n",
    "\n",
    "#Read File\n",
    "train_index = test_index = 0\n",
    "for i, line in enumerate(f):\n",
    "    if i >= 1: #Skip the first header line\n",
    "        split_line = line.split(\",\")\n",
    "        usage = split_line[2].rstrip()\n",
    "        if usage == 'Training':\n",
    "            X_train[train_index, :,:] = np.fromstring(split_line[1], dtype = 'int', sep = ' ').reshape(dim, dim)\n",
    "            y_train[train_index] = int(split_line[0])\n",
    "            train_index += 1\n",
    "        elif usage == 'PublicTest':\n",
    "            X_test[test_index, :,:] = np.fromstring(split_line[1], dtype = 'int', sep = ' ').reshape(dim, dim)\n",
    "            y_test[test_index] = int(split_line[0])\n",
    "            test_index += 1\n",
    "\n",
    "print ('Initial shape',X_train.shape)\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "#Number of classes in the output\n",
    "nb_classes = 7\n",
    "\n",
    "#Number of epochs\n",
    "nb_epoch = 50\n",
    "\n",
    "# Image dimensions\n",
    "img_rows, img_cols = 48, 48\n",
    "\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 32\n",
    "\n",
    "# size of pooling area for max pooling\n",
    "nb_pool = 2\n",
    "\n",
    "# convolution kernel size\n",
    "nb_conv = 3\n",
    "\n",
    "#Reshape Train and Test samples as binary matrices\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "X_train = X_train.astype(\"float32\")\n",
    "X_train /= 255\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "X_test = X_test.astype(\"float32\")\n",
    "X_test /= 255\n",
    "\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "#Output vectors to single column binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "print('Y_train shape',Y_train.shape)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#First Convolutional Layer with Rectified Linear Unit\n",
    "model.add(Convolution2D(nb_filters, (nb_conv, nb_conv), padding=\"full\", input_shape=(1, img_rows, img_cols),activation='relu'))\n",
    "\n",
    "#Second Convolutional Layer with Rectified Linear Unit\n",
    "model.add(Convolution2D(nb_filters, (nb_conv, nb_conv),activation='relu'))\n",
    "\n",
    "#Third Convolutional Layer with Rectified Linear Unit\n",
    "model.add(Convolution2D(nb_filters, (nb_conv, nb_conv),activation='relu'))\n",
    "\n",
    "#Pooling Layer - Max Pooling \n",
    "model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n",
    "\n",
    "#4th Convolutional Layer with Rectified Linear Unit\n",
    "model.add(Convolution2D(64, (nb_conv, nb_conv),activation='relu'))\n",
    "\n",
    "#5th Convolutional Layer with Rectified Linear Unit\n",
    "model.add(Convolution2D(64, (nb_conv, nb_conv),activation='relu'))\n",
    "\n",
    "#6th Convolutional Layer with Rectified Linear Unit\n",
    "model.add(Convolution2D(64, (nb_conv, nb_conv),activation='relu'))\n",
    "\n",
    "#Pooling Layer - Max Pooling \n",
    "model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n",
    "\n",
    "#7th Convolutional Layer with Rectified Linear Unit\n",
    "model.add(Convolution2D(128, (nb_conv, nb_conv),activation='relu'))\n",
    "\n",
    "#8th Convolutional Layer with Rectified Linear Unit\n",
    "model.add(Convolution2D(128, (nb_conv, nb_conv),activation='relu'))\n",
    "\n",
    "#9th Convolutional Layer with Rectified Linear Unit\n",
    "model.add(Convolution2D(128, (nb_conv, nb_conv),activation='relu'))\n",
    "\n",
    "#Pooling Layer - Max Pooling \n",
    "model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n",
    "\n",
    "#Reduce overfitting\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#Convert to 1D vectors\n",
    "model.add(Flatten())\n",
    "\n",
    "#Change dimensions\n",
    "model.add(Dense(128,activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes))\n",
    "\n",
    "#Probabilities sum to 1.0\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, initial_epoch=0, verbose=1, validation_data=(X_test, Y_test))\n",
    "\n",
    "loss,accuracy = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print(model.metrics_names)\n",
    "print('Test score:', loss)\n",
    "print('Test accuracy:', accuracy)\n",
    "\n",
    "#Classify into Classes\n",
    "predictions=np.empty(test_size)\n",
    "predictions=model.predict_classes(X_test, batch_size=batch_size, verbose=1)\n",
    "print('Predictions:',predictions)\n",
    "#for x in np.nditer(predictions):\n",
    "#    print(x)\n",
    "\n",
    "#Probabilities\n",
    "probs=model.predict_proba(X_test, batch_size=batch_size, verbose=1)\n",
    "print('Probablities:')\n",
    "#for x in np.nditer(probs):\n",
    "#    print(x)\n",
    "print(probs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
